{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "\n",
    "files_normaly = sorted(glob.glob(os.path.abspath('../input/train/*/normal/*.wav')))\n",
    "files_anomaly = sorted(glob.glob(os.path.abspath('../input/train/*/anomaly/*.wav')))\n",
    "files_test = sorted(glob.glob(os.path.abspath('../input/test/*.wav')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = []\n",
    "for file in files_normaly:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    normal.append(y)\n",
    "\n",
    "normal = np.array(normal)\n",
    "\n",
    "anomaly = []\n",
    "for file in files_anomaly:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    anomaly.append(y)\n",
    "anomaly = np.array(anomaly)\n",
    "\n",
    "test = []\n",
    "for file in files_test:\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    test.append(y)\n",
    "test = np.array(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec_normal = []\n",
    "for n in normal:\n",
    "    m = librosa.feature.melspectrogram(n, n_mels=256)\n",
    "    m = librosa.power_to_db(m).astype(np.float32)\n",
    "    melspec_normal.append(m)\n",
    "melspec_normal = np.array(melspec_normal)\n",
    "\n",
    "melspec_anomaly = []\n",
    "for a in anomaly:\n",
    "    m = librosa.feature.melspectrogram(a, n_mels=256)\n",
    "    m = librosa.power_to_db(m).astype(np.float32)\n",
    "    melspec_anomaly.append(m)\n",
    "melspec_anomaly = np.array(melspec_anomaly)\n",
    "\n",
    "melspec_test = []\n",
    "for t in test:\n",
    "    m = librosa.feature.melspectrogram(t, n_mels=256)\n",
    "    m = librosa.power_to_db(m).astype(np.float32)\n",
    "    melspec_test.append(m)\n",
    "melspec_test = np.array(melspec_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.concatenate([melspec_normal, melspec_anomaly])\n",
    "train = train.reshape(train.shape[0],-1)\n",
    "\n",
    "\n",
    "train_Y = np.concatenate([np.zeros(len(melspec_normal)), np.ones(len(melspec_anomaly))])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train, train_Y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\n",
    "                            GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train_X.shape[0]\n",
    "ntest = test_Y.shape[0]\n",
    "SEED = 0\n",
    "NFOLDS = 4\n",
    "kf = KFold(n_splits=NFOLDS)\n",
    "\n",
    "class SkearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.clf.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        return self.clf.fit(x, y)\n",
    "\n",
    "    def feature_importances(self, x, y):\n",
    "        print(self.clf.fit(x, y).feature_importances_)\n",
    "\n",
    "\n",
    "\n",
    "def get_oof(clf, X_train, y_train, X_test):\n",
    "    oof_train = np.zeros((ntrain, ))\n",
    "    oof_test = np.zeros((ntest, ))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        x_tr = X_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = X_train[test_index]\n",
    "        y_te = y_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(test_X)\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1,1), oof_test.reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "    'warm_start': True,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features': 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.7,\n",
    "}\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'kernel': 'linear',\n",
    "    'C': 0.025\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma/.bin/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/home/ma/.bin/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/home/ma/.bin/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    }
   ],
   "source": [
    "rf = SkearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SkearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "gb = SkearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SkearnHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "ada = SkearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "\n",
    "\n",
    "et_oof_train, et_oof_test = get_oof(et, train_X, train_Y, test_X)\n",
    "rf_oof_train, rf_oof_test = get_oof(rf, train_X, train_Y, test_X)\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, train_X, train_Y, test_X)\n",
    "gb_oof_train, gb_oof_test = get_oof(gb, train_X, train_Y, test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
